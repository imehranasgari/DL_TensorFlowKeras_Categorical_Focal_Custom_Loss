{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X92cEw1w8Kit"
   },
   "source": [
    "## Categorical Focal Loss\n",
    "In this assignment we will implement a categorical focal loss function with \"L1\" and \"L2\" regularization for multi-class classification problems.\\\n",
    "Focal Loss have several applications in problems which have inbalance datasets such as Object Detection:\n",
    "you can learn more about this loss function here:\n",
    "https://medium.com/swlh/focal-loss-what-why-and-how-df6735f26616"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "X3bSV4DJ8GXM",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 2.1.3\n",
      "TensorFlow version: 2.19.0\n",
      "Available GPUs: []\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "print(\"NumPy version:\", numpy.__version__)\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Available GPUs:\", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "The article you sent is about **Focal Loss**, a well-known loss function designed for **imbalanced classification problems**, especially in fields like **object detection** (such as the RetinaNet model). Let's break it down simply and precisely:\n",
    "\n",
    "***\n",
    "\n",
    "## ‚úÖ Main Issue: Class Imbalance\n",
    "\n",
    "In many problems (like cancer detection or object recognition in images), positive class samples are much fewer than negative class samples. For example:\n",
    "\n",
    "- 99% of the data is ‚Äúnon-cancer‚Äù\n",
    "- 1% of the data is ‚Äúcancer‚Äù\n",
    "\n",
    "A model that always predicts ‚Äúnon-cancer‚Äù will still have 99% accuracy‚Äîbut is completely useless in practice.\n",
    "\n",
    "***\n",
    "\n",
    "## ‚ùó What‚Äôs the problem with Binary Cross-Entropy?\n",
    "\n",
    "The BCE loss function treats easy samples (which the model predicts correctly) and hard samples (which the model predicts incorrectly) equally.  \n",
    "In an imbalanced dataset, there are many easy samples ‚Üí the model just learns to predict them ‚Üí the minority class gets ignored.\n",
    "\n",
    "***\n",
    "\n",
    "## ‚úÖ Solution: Focal Loss\n",
    "\n",
    "### üìå Focal Loss Formula (binary):\n",
    "\n",
    "For a single sample:\n",
    "\n",
    "$$\n",
    "FL(p_t) = - \\alpha_t \\cdot (1 - p_t)^\\gamma \\cdot \\log(p_t)\n",
    "$$\n",
    "\n",
    "#### Parameter Explanations:\n",
    "\n",
    "- $$ p_t $$: The predicted probability for the true class (if y=1 ‚Üí p, if y=0 ‚Üí 1‚àíp)\n",
    "- $$ \\alpha_t $$: Weight for each class (to address class imbalance)\n",
    "- $$ \\gamma $$: **Focusing parameter** ‚Äì controls how much the loss focuses on hard samples\n",
    "\n",
    "***\n",
    "\n",
    "## ‚úÖ Role of Œ≥ (gamma)\n",
    "\n",
    "- If $$ \\gamma = 0 $$, focal loss is just ordinary cross-entropy.\n",
    "- The larger $$ \\gamma $$ is, the less the loss is affected by **easy samples** (those the model already predicts well).\n",
    "- This forces the model to focus on **hard samples**.\n",
    "\n",
    "***\n",
    "\n",
    "## ‚úÖ Role of Œ± (alpha)\n",
    "\n",
    "- A number between 0 and 1 that helps emphasize the minority class.\n",
    "- For example, if class 1 is the minority, you might set $$ \\alpha = 0.75 $$ for class 1 and $$ 1 - \\alpha = 0.25 $$ for class 0.\n",
    "\n",
    "***\n",
    "\n",
    "## ‚ú≥Ô∏è Simple Example\n",
    "\n",
    "Suppose the model predicts 0.95 probability for the correct class (i.e., it‚Äôs an easy example):\n",
    "\n",
    "- With **cross-entropy**, you get a low loss, but it‚Äôs still counted equally\n",
    "- With focal loss and $$ \\gamma = 2 $$, the loss is much smaller‚Äîso the model pays less attention to this easy sample\n",
    "\n",
    "***\n",
    "\n",
    "## üìà Common Applications of Focal Loss:\n",
    "\n",
    "- Object Detection (RetinaNet)\n",
    "- Imbalanced Binary Classification (e.g., fraud detection, cancer classification)\n",
    "- Face verification, anomaly detection\n",
    "\n",
    "***\n",
    "\n",
    "## ‚úÖ Simple Summary\n",
    "\n",
    "| Case    | Explanation                                                                    |\n",
    "|---------|--------------------------------------------------------------------------------|\n",
    "| Issue   | Data imbalance makes the model focus on learning easy/majority samples          |\n",
    "| Solution| Focal loss **down-weights** easy samples                                       |\n",
    "| Œ≥ (gamma) | Controls the focus on hard samples                                           |\n",
    "| Œ± (alpha) | Balances classes in case of imbalance                                        |\n",
    "\n",
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i9ZjwB5c980p"
   },
   "source": [
    "Let me rewrite the Focal Loss formula and the associated loss terms in a more logical and readable format, with each equation on a new line as requested.\n",
    "\n",
    "Focal Loss Formula:\n",
    "\n",
    "$$\n",
    "FL(y_{true}, y_{pred}) = - \\alpha * y_{true} * (1 - y_{pred})^Œ≥ * log(y_{pred})\n",
    "$$\n",
    "\n",
    "$$\n",
    "l1(y_{true}, y_{pred}) = \\sum |y_{pred}|\n",
    "$$\n",
    "\n",
    "$$\n",
    "l2(y_{true}, y_{pred}) = \\sum (y_{pred})^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "total.loss = FL + l1_w * l1 + l2_w * l2\n",
    "$$\n",
    "\n",
    "This format places each equation on a new line after the equals sign, making it easier to follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class CategoricalFocalLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, l1=0.0, l2=0.0, **kwargs):\n",
    "        \"\"\"\n",
    "        Ÿæÿßÿ±ÿßŸÖÿ™ÿ±Ÿáÿß:\n",
    "         - alpha: ÿ∂ÿ±€åÿ® ÿ™ÿπÿßÿØŸÑ ⁄©ŸÑÿßÿ≥‚ÄåŸáÿß (ŸÖÿπŸÖŸàŸÑÿßŸã ÿ®ÿ±ÿß€å ⁄©ŸÑÿßÿ≥‚ÄåŸáÿß€å ŸÜÿßŸÖÿ™Ÿàÿßÿ≤ŸÜ)\n",
    "         - gamma: ÿ∂ÿ±€åÿ® ÿ™ŸÖÿ±⁄©ÿ≤ ÿ±Ÿà€å ŸÜŸÖŸàŸÜŸá‚ÄåŸáÿß€å ÿ≥ÿÆÿ™ (focusing parameter)\n",
    "         - l1: ÿ∂ÿ±€åÿ® ŸÖŸÜÿ∏ŸÖ‚Äåÿ≥ÿßÿ≤€å L1 ÿ±Ÿà€å Ÿæ€åÿ¥‚Äåÿ®€åŸÜ€å‚ÄåŸáÿß (y_pred)\n",
    "         - l2: ÿ∂ÿ±€åÿ® ŸÖŸÜÿ∏ŸÖ‚Äåÿ≥ÿßÿ≤€å L2 ÿ±Ÿà€å Ÿæ€åÿ¥‚Äåÿ®€åŸÜ€å‚ÄåŸáÿß (y_pred)\n",
    "        \"\"\"\n",
    "        super(CategoricalFocalLoss, self).__init__(**kwargs)\n",
    "        self.alpha = alpha          # Ÿàÿ≤ŸÜ‚ÄåÿØŸá€å ÿ®Ÿá ⁄©ŸÑÿßÿ≥‚ÄåŸáÿß\n",
    "        self.gamma = gamma          # ÿ™ŸÖÿ±⁄©ÿ≤ ÿ±Ÿà€å ŸÜŸÖŸàŸÜŸá‚ÄåŸáÿß€å ÿ≥ÿÆÿ™\n",
    "        self.l1_weight = l1         # ÿ∂ÿ±€åÿ® L1\n",
    "        self.l2_weight = l2         # ÿ∂ÿ±€åÿ® L2\n",
    "\n",
    "        def call (self, y_true, y_pred):\n",
    "            y_pred = tf.clip_by_value(y_pred, clip_value_min =1e-7, clip_value_max =1 - 1e-7 )\n",
    "            focal = -self.alpha * (y_true)* tf.pow((1 - y_pred), self.gamma) * tf.math.log(y_pred)\n",
    "            focal_class = rf.reduce_sum(focal,axis =1)\n",
    "            focal_class_batch = tf.reduce_mean(focal_class)\n",
    "            \n",
    "            l1 = tf.math.reduce_sum(tf.math.abs(y_pred))\n",
    "            l2 = tf.math.reduce_sum(tf.math.square(y_pred))\n",
    "        return focal_class_batch+ l1*self.l1_weight + l2* self.l2_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DTf7IwJd86pQ"
   },
   "outputs": [],
   "source": [
    "class CategoricalFocalLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, l1=0.0, l2=0.0, **kwargs):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "         - alpha: Class balancing factor (usually for imbalanced classes)\n",
    "         - gamma: Focusing parameter for hard samples\n",
    "         - l1: L1 regularization weight on predictions (y_pred)\n",
    "         - l2: L2 regularization weight on predictions (y_pred)\n",
    "        \"\"\"\n",
    "        super(CategoricalFocalLoss, self).__init__(**kwargs)\n",
    "        self.alpha = alpha           # Class weighting\n",
    "        self.gamma = gamma           # Focus on hard samples\n",
    "        self.l1_weight = l1          # L1 coefficient\n",
    "        self.l2_weight = l2          # L2 coefficient\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Computes the final loss, including:\n",
    "          1. Multiclass focal loss\n",
    "          2. L1 regularization on y_pred\n",
    "          3. L2 regularization on y_pred\n",
    "        \"\"\"\n",
    "        # 1. Prevent log(0)\n",
    "        #    To avoid log(0) and prevent NaNs\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1.0 - 1e-7)\n",
    "\n",
    "        # 2. Compute focal loss term:\n",
    "        #    -y_true * (1 - y_pred)^gamma * log(y_pred)\n",
    "        #    Then multiply by alpha and sum across classes\n",
    "        #    Shape: [batch_size, num_classes]\n",
    "        focal_term = - self.alpha * y_true * tf.pow(1.0 - y_pred, self.gamma) * tf.math.log(y_pred)\n",
    "        # Sum across the class axis ‚Üí vector of [batch_size]\n",
    "        focal_loss_per_sample = tf.reduce_sum(focal_term, axis=1)\n",
    "        # Mean over the whole batch\n",
    "        focal_loss = tf.reduce_mean(focal_loss_per_sample)\n",
    "\n",
    "        # 3. L1 regularization:\n",
    "        #    Sum of absolute values of y_pred over entire batch and all classes\n",
    "        #    L1 = sum(|y_pred|)\n",
    "        l1_term = tf.reduce_sum(tf.abs(y_pred))\n",
    "\n",
    "        # 4. L2 regularization:\n",
    "        #    Sum of squares of y_pred over entire batch and all classes\n",
    "        #    L2 = sum((y_pred)^2)\n",
    "        l2_term = tf.reduce_sum(tf.square(y_pred))\n",
    "\n",
    "        # 5. Combine all components:\n",
    "        #    total_loss = focal_loss + l1_weight * L1 + l2_weight * L2\n",
    "        total_loss = (\n",
    "            focal_loss\n",
    "            + self.l1_weight * l1_term\n",
    "            + self.l2_weight * l2_term\n",
    "        )\n",
    "\n",
    "        return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Hc6pe74GEnAK"
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_model(dense_units, input_shape=(224, 224) + (3,)):\n",
    "  model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=input_shape),\n",
    "      tf.keras.layers.MaxPooling2D(2, 2),\n",
    "      tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2, 2),\n",
    "      tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2, 2),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(dense_units, activation='relu'),\n",
    "      tf.keras.layers.Dense(2, activation='softmax')\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0YtH-VbM91oC",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "\n",
    "# 1) Force fresh download\n",
    "tfds.core.utils.gcs_utils._is_gcs_disabled = True\n",
    "data_dir = os.path.normpath('C:/Users/AERO/tensorflow_datasets')\n",
    "dataset = tfds.load('cats_vs_dogs', split='train', data_dir=data_dir, download=True)\n",
    "\n",
    "\n",
    "# 2) Preprocessing\n",
    "def preprocess(features):\n",
    "    img = tf.image.resize(features['image'], (224, 224))\n",
    "    img = tf.cast(img, tf.float32) / 255.\n",
    "    label = tf.one_hot(features['label'], 2)\n",
    "    return img, tf.cast(label, tf.float32)\n",
    "\n",
    "dataset = dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "dataset = dataset.shuffle(1000).batch(32).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# 3) Build, compile, fit\n",
    "model = build_model(dense_units=256)  \n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=CategoricalFocalLoss(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(dataset, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.10.0\n",
      "Num GPUs Available: 1\n",
      "WARNING:tensorflow:From C:\\Users\\AERO\\AppData\\Local\\Temp\\ipykernel_18516\\2951423711.py:4: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "TensorFlow is using GPU: True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"TensorFlow is using GPU:\", tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GPU detected: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"‚úÖ GPU detected:\", gpus)\n",
    "else:\n",
    "    print(\"‚ùå No GPU found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0\n",
      "Available GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Available GPUs:\", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPdAeh4gDzxN9JIViJggC/K",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
